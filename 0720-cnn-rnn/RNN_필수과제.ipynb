{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recurrent Neural Networks - 필수 과제**\n",
    "\n",
    "**LSTM**을 구현해봅시다!\n",
    "<br><br><br>\n",
    "**필요 사전 지식**:\n",
    "\n",
    "- <u>PyTorch</u> (선택 과제 1)\n",
    "\n",
    "<br>\n",
    "\n",
    "**추가 사전 지식**: (알면 좋으나 몰라도 괜찮음)\n",
    "\n",
    "- <u>Tokenization</u>, <u>Word Embedding</u> (선택 과제 2)\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "[Hugging Face](https://huggingface.co)에서 [Rotten Tomatoes dataset](https://huggingface.co/datasets/rotten_tomatoes)과 [pretrained BERT](https://huggingface.co/bert-base-uncased)의 tokenizer를 가져오겠습니다.\n",
    "\n",
    "또 학습 부담을 줄이기 위해 pretrained BERT에 내장된 word embedding layer의 weight도 가져옵시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "100%|██████████| 3/3 [00:00<00:00, 708.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/rotten_tomatoes\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "# https://huggingface.co/bert-base-uncased\n",
    "pretrained_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "pretrained_embeddings = AutoModel.from_pretrained(\"bert-base-uncased\").embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "기본 BERT는 token을 768차원 벡터로 embedding합니다. 우리의 작은 dataset과 작은 모델에게 768차원은 부담스러우니 PCA를 사용해 64차원으로 줄여줍시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nano_embed = torch.pca_lowrank(pretrained_embeddings.weight.detach(), q=64)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "그런데 무작정 64차원으로 줄여도 되는 걸까요? BERT의 d_model이 괜히 768도 아닐 테고, 정보의 손실이 아주 클 것 같은데 말입니다.\n",
    "\n",
    "궁금하니 코사인 유사도로 축소된 embedding layer에 token들의 정보가 그럭저럭 잘 남아있는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = (nano_embed @ nano_embed.T) / (nano_embed.abs() @ nano_embed.abs().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people',\n",
       " 'jeff',\n",
       " 'population',\n",
       " 'reid',\n",
       " 'catherine',\n",
       " 'taylor',\n",
       " 'governmental',\n",
       " 'many',\n",
       " 'mental',\n",
       " 'musicians',\n",
       " 'several',\n",
       " 'six',\n",
       " 'ka',\n",
       " 'ana',\n",
       " 'they',\n",
       " 'moving',\n",
       " 'steven',\n",
       " 'god',\n",
       " 'her',\n",
       " 'demographic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word에 다양한 값을 넣어보세요! tokenizer의 vocab에 없는 token에 대해서는 빈 list가 뜹니다.\n",
    "word = \"jackson\"\n",
    "\n",
    "([*map(pretrained_tokenizer.decode, cos[pretrained_tokenizer.vocab[word]].argsort(descending=True)[1:21])] if word in pretrained_tokenizer.vocab else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "꽤 잘 남아있는 것 같습니다.\n",
    "\n",
    "(TMI: 조금 더 욕심을 부려 한번 32차원으로 줄여보면 무시하기 어려운 정보의 손실을 체감할 수 있습니다.)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 LSTM을 구현합시다! 사실 원래 BiLSTM으로 하려고 했는데 underfitting이 심해서 그냥 plain LSTM으로 준비했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "#### <span style=\"color:red\">**<u>Q1.</u>**</span>\n",
    "\n",
    "`class LSTMCell`의 빈칸을 채우세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, d_x, d_h): # d_x: x의 차원수 (scalar int)\n",
    "                                  # d_h: h의 차원수 (scalar int)\n",
    "        super().__init__()\n",
    "        d_stack = d_x + d_h\n",
    "        ######################### START OF YOUR CODE #########################\n",
    "        \n",
    "        dim1 = # FILL HERE\n",
    "        dim2 = # FILL HERE\n",
    "        dim3 = # FILL HERE\n",
    "        dim4 = # FILL HERE\n",
    "        dim5 = # FILL HERE\n",
    "        dim6 = # FILL HERE\n",
    "        \n",
    "        ########################## END OF YOUR CODE ##########################\n",
    "        self.W_f = nn.Linear(d_stack, d_h)\n",
    "        self.W_i = nn.Linear(dim1, dim2)\n",
    "        self.W_C = nn.Linear(dim3, dim4)\n",
    "        self.W_o = nn.Linear(dim5, dim6)\n",
    "    \n",
    "    \n",
    "    # forward는 t-1의 h_{t-1}, C_{t-1}과 t의 x_t를 입력으로 받아 계산합니다.\n",
    "    \n",
    "    def forward(self, x, h, C): # x: x_t\n",
    "                                # h: h_{h-1}\n",
    "                                # C: C_{t-1}\n",
    "        stack = torch.cat([x, h])\n",
    "        ######################### START OF YOUR CODE #########################\n",
    "        \n",
    "        f =   # FILL HERE\n",
    "        i =   # FILL HERE\n",
    "        C_ =  self.W_C(stack).tanh()\n",
    "\n",
    "        C_t = f * C + i * C_\n",
    "        \n",
    "        o =   # FILL HERE\n",
    "        h_t = # FILL HERE\n",
    "        \n",
    "        ########################## END OF YOUR CODE ##########################\n",
    "        return h_t, C_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_out, pretrained_embeddings):\n",
    "        super().__init__()\n",
    "        vocab_size = pretrained_embeddings.shape[0]\n",
    "        d_h = d_model = pretrained_embeddings.shape[1]\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, d_model, _weight=pretrained_embeddings.clone()) # word embedding layer\n",
    "        self.cell = LSTMCell(d_x=d_model, d_h=d_h) # LSTM cell\n",
    "        self.out = nn.Linear(d_h, d_out, bias=True) # output layer\n",
    "\n",
    "        self.h_init = nn.Parameter(torch.zeros(d_h), requires_grad=False) # initial h\n",
    "        self.C_init = nn.Parameter(torch.zeros(d_h), requires_grad=False) # initial C\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        embedded = self.embed(input_ids).squeeze()\n",
    "\n",
    "        h = self.h_init.clone() # h 초기화\n",
    "        C = self.C_init.clone() # C 초기화\n",
    "        for x in embedded:\n",
    "            h, C = self.cell(x, h, C) # iterate over embedded sequence\n",
    "        \n",
    "        return self.out(h).squeeze() # last hidden state를 output layer에 통과시킨 값을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "#### <span style=\"color:red\">**<u>Q2.</u>**</span>\n",
    "\n",
    "Test accuracy가 0.7 이상이 되도록 모델을 훈련시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### START OF YOUR CODE #########################\n",
    "\n",
    "# 필요에 따라 바꿔도 됩니다.\n",
    "device = \"cuda\"\n",
    "\n",
    "########################## END OF YOUR CODE ##########################\n",
    "\n",
    "model = LSTM(vocab_size=pretrained_tokenizer.vocab_size, d_out=1, pretrained_embeddings=nano_embed).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### START OF YOUR CODE #########################\n",
    "\n",
    "# learning rate을 적절히 수정해보세요.\n",
    "lr = 2.5e-03\n",
    "\n",
    "########################## END OF YOUR CODE ##########################\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset[\"train\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 505/8530 [00:13<03:21, 39.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  500 iter: 0.6931292682886123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1003/8530 [00:27<03:37, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1000 iter: 1.0969898758880445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1504/8530 [00:41<03:12, 36.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1500 iter: 0.6903957996368408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2004/8530 [00:55<03:14, 33.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 iter: 0.6857238532304764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2506/8530 [01:09<02:47, 35.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2500 iter: 0.6456294469237328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3006/8530 [01:23<02:50, 32.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3000 iter: 0.6523887581154704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3504/8530 [01:36<02:23, 35.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3500 iter: 0.6221277821231633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4003/8530 [01:49<01:53, 40.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4000 iter: 0.5925953171071887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4505/8530 [02:02<01:39, 40.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4500 iter: 0.5855336117818951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 5004/8530 [02:15<01:40, 35.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5000 iter: 0.5884635599926115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 5503/8530 [02:28<01:21, 37.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5500 iter: 0.5609503022283315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 6005/8530 [02:42<01:12, 34.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6000 iter: 0.6745002037400991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 6504/8530 [02:56<00:57, 35.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6500 iter: 0.5486738329646186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 7006/8530 [03:10<00:43, 34.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7000 iter: 0.5677068214089668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7507/8530 [03:22<00:23, 42.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7500 iter: 0.5383648603819311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 8009/8530 [03:35<00:11, 45.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8000 iter: 0.5486359189599752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 8506/8530 [03:48<00:00, 35.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8500 iter: 0.5498053788281977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8530/8530 [03:49<00:00, 37.16it/s]\n"
     ]
    }
   ],
   "source": [
    "######################### START OF YOUR CODE #########################\n",
    "\n",
    "# 필요에 따라 바꿔도 됩니다.\n",
    "num_print = 500\n",
    "num_batch = 10\n",
    "\n",
    "########################## END OF YOUR CODE ##########################\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "save_l = 0\n",
    "optimizer.zero_grad()\n",
    "for i, data in enumerate(tqdm(train_loader)):\n",
    "    text, label = data[\"text\"][0], data[\"label\"][0]\n",
    "    input_ids = pretrained_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    y_pred = model(input_ids)\n",
    "\n",
    "    label = label.to(device) * 1.\n",
    "    loss = criterion(y_pred, label)\n",
    "    loss.backward()\n",
    "    \n",
    "    if not (i+1)%num_batch:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    save_l += loss.item()\n",
    "    if not (i+1)%num_print:\n",
    "        print(f\"{i+1:>5} iter: {save_l/num_print}\")\n",
    "        save_l = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset[\"test\"], shuffle=True)\n",
    "\n",
    "\n",
    "# test\n",
    "\n",
    "res = torch.tensor(0)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        text, label = data[\"text\"][0], data[\"label\"][0]\n",
    "        input_ids = pretrained_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "        y_pred = model(input_ids)\n",
    "        res += ((1 if y_pred > 0 else 0) == label)\n",
    "\n",
    "print(\"Test accuracy:\", res.item() / dataset[\"test\"].num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'return to never land is much more p . c . than the original version ( no more racist portraits of indians , for instance ) , but the excitement is missing .', 'label': 0}\n",
      "0.3866649568080902\n"
     ]
    }
   ],
   "source": [
    "# 관찰용\n",
    "# n 값을 바꿔가며 훈련시킨 모델의 예측값을 구경해보세요\n",
    "n = 589\n",
    "\n",
    "print(dataset[\"test\"][n])\n",
    "with torch.no_grad():\n",
    "    print(model(pretrained_tokenizer.encode(dataset[\"test\"][n][\"text\"], return_tensors=\"pt\").to(device)).sigmoid().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
